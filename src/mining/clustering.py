"""
Module ph√¢n c·ª•m kh√°ch h√†ng
ƒê√É LO·∫†I B·ªé duration ƒë·ªÉ tr√°nh insights sai l·ªách
"""
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, davies_bouldin_score
import yaml
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CustomerClustering:
    """Ph√¢n c·ª•m kh√°ch h√†ng d·ª±a tr√™n h·ªì s∆° t√†i ch√≠nh - KH√îNG D√ôNG duration"""
    
    def __init__(self, config_path="configs/params.yaml"):
        with open(config_path, 'r') as f:
            self.config = yaml.safe_load(f)
        
        self.n_clusters = self.config['clustering']['n_clusters']
        self.random_state = self.config['clustering']['random_state']
    
    def _remove_duration_from_features(self, feature_list):
        """Lo·∫°i b·ªè duration kh·ªèi danh s√°ch features"""
        if 'duration' in feature_list:
            logger.warning("‚ö†Ô∏è  Removing 'duration' from clustering features")
            logger.warning("   (duration causes misleading insights)")
            return [f for f in feature_list if f != 'duration']
        return feature_list
    
    def prepare_clustering_features(self, df):
        """
        Chu·∫©n b·ªã features cho ph√¢n c·ª•m
        ƒê√É LO·∫†I B·ªé duration
        """
        # Ch·ªçn c√°c features li√™n quan ƒë·∫øn h·ªì s∆° t√†i ch√≠nh (KH√îNG duration)
        financial_features = ['age', 'balance', 'campaign', 'previous']
        #                                 ^ ƒê√É LO·∫†I B·ªé duration
        
        # Th√™m c√°c ƒë·∫∑c tr∆∞ng ƒë√£ ƒë∆∞·ª£c x√¢y d·ª±ng
        if 'RFM_score' in df.columns:
            financial_features.extend(['R_score', 'F_score', 'M_score', 'RFM_score'])
        
        if 'has_debt' in df.columns:
            financial_features.append('has_debt')
        
        if 'was_contacted_before' in df.columns:
            financial_features.append('was_contacted_before')
        
        # Lo·∫°i b·ªè duration (an to√†n)
        financial_features = self._remove_duration_from_features(financial_features)
        
        # L·ªçc c√°c features c√≥ trong dataframe
        available_features = [f for f in financial_features if f in df.columns]
        
        logger.info(f"Clustering features (safe, no duration): {available_features}")
        
        X_cluster = df[available_features].copy()
        
        # X·ª≠ l√Ω gi√° tr·ªã v√¥ h·∫°n ho·∫∑c NaN
        X_cluster = X_cluster.replace([np.inf, -np.inf], np.nan)
        X_cluster = X_cluster.fillna(X_cluster.mean())
        
        # Chu·∫©n h√≥a
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_cluster)
        
        return X_scaled, scaler, available_features
    
    def find_optimal_k(self, X, max_k=10):
        """T√¨m s·ªë c·ª•m t·ªëi ∆∞u b·∫±ng elbow method v√† silhouette score"""
        inertias = []
        silhouettes = []
        
        for k in range(2, max_k + 1):
            kmeans = KMeans(n_clusters=k, random_state=self.random_state, n_init=10)
            labels = kmeans.fit_predict(X)
            
            inertias.append(kmeans.inertia_)
            try:
                sil = silhouette_score(X, labels)
                silhouettes.append(sil)
                logger.info(f"K={k}: inertia={kmeans.inertia_:.2f}, silhouette={sil:.4f}")
            except:
                silhouettes.append(-1)
                logger.info(f"K={k}: inertia={kmeans.inertia_:.2f}, silhouette= N/A")
        
        return inertias, silhouettes
    
    def perform_clustering(self, X, n_clusters=None):
        """Th·ª±c hi·ªán ph√¢n c·ª•m K-means"""
        if n_clusters is None:
            n_clusters = self.n_clusters
        
        logger.info(f"Performing K-means clustering with {n_clusters} clusters")
        
        kmeans = KMeans(n_clusters=n_clusters, random_state=self.random_state, n_init=10)
        cluster_labels = kmeans.fit_predict(X)
        
        # ƒê√°nh gi√°
        try:
            silhouette = silhouette_score(X, cluster_labels)
        except:
            silhouette = -1
            logger.warning("Could not compute silhouette score")
        
        try:
            davies_bouldin = davies_bouldin_score(X, cluster_labels)
        except:
            davies_bouldin = -1
            logger.warning("Could not compute Davies-Bouldin score")
        
        logger.info(f"Silhouette Score: {silhouette:.4f}")
        logger.info(f"Davies-Bouldin Index: {davies_bouldin:.4f}")
        
        return cluster_labels, kmeans, silhouette, davies_bouldin
    
    def profile_clusters(self, df, cluster_labels):
        """
        T·∫°o h·ªì s∆° cho t·ª´ng c·ª•m
        KH√îNG D√ôNG duration trong profile
        """
        df_profile = df.copy()
        df_profile['Cluster'] = cluster_labels
        
        # T√≠nh to√°n c√°c ƒë·∫∑c tr∆∞ng cho t·ª´ng c·ª•m (KH√îNG duration)
        numeric_cols = ['age', 'balance', 'campaign', 'previous']
        #                                 ^ ƒê√É LO·∫†I B·ªé duration
        
        if 'RFM_score' in df.columns:
            numeric_cols.extend(['R_score', 'F_score', 'M_score', 'RFM_score'])
        
        if 'was_contacted_before' in df.columns:
            numeric_cols.append('was_contacted_before')
        
        if 'has_debt' in df.columns:
            numeric_cols.append('has_debt')
        
        # Lo·∫°i b·ªè duration n·∫øu c√≤n s√≥t
        numeric_cols = self._remove_duration_from_features(numeric_cols)
        
        # L·ªçc c√°c c·ªôt t·ªìn t·∫°i
        numeric_cols = [col for col in numeric_cols if col in df_profile.columns]
        
        cluster_profile = df_profile.groupby('Cluster')[numeric_cols].agg(['mean', 'std', 'count'])
        
        # T√≠nh t·ª∑ l·ªá ƒëƒÉng k√Ω th√†nh c√¥ng theo c·ª•m
        if 'y' in df_profile.columns:
            success_rate = df_profile.groupby('Cluster')['y'].mean()
            cluster_profile[('y_success_rate', 'mean')] = success_rate
        
        # Th·ªëng k√™ categorical
        cat_cols = ['job', 'marital', 'education', 'housing', 'loan']
        cat_profiles = {}
        for col in cat_cols:
            if col in df_profile.columns:
                try:
                    cat_profiles[col] = df_profile.groupby('Cluster')[col].value_counts(normalize=True).unstack().fillna(0)
                except:
                    pass
        
        return cluster_profile, cat_profiles
    
    def get_cluster_insights(self, df, cluster_labels):
        """
        R√∫t insight t·ª´ c√°c c·ª•m
        KH√îNG D√ôNG duration trong insights
        """
        df_insight = df.copy()
        df_insight['Cluster'] = cluster_labels
        
        insights = []
        total_customers = len(df_insight)
        
        # C·∫£nh b√°o n·∫øu v·∫´n c√≤n duration
        if 'duration' in df_insight.columns:
            logger.warning("‚ö†Ô∏è  'duration' exists but excluded from clustering insights")
        
        # Ph√¢n t√≠ch t·ª´ng c·ª•m
        for cluster in sorted(df_insight['Cluster'].unique()):
            cluster_data = df_insight[df_insight['Cluster'] == cluster]
            
            # ƒê·∫∑c ƒëi·ªÉm c∆° b·∫£n (KH√îNG duration)
            size = len(cluster_data)
            age_mean = cluster_data['age'].mean()
            balance_mean = cluster_data['balance'].mean()
            campaign_mean = cluster_data['campaign'].mean()
            previous_mean = cluster_data['previous'].mean()
            
            insight = f"\nC·ª•m {cluster} ({size} kh√°ch h√†ng - {size/total_customers*100:.1f}%):"
            insights.append(insight)
            insights.append(f"- Tu·ªïi trung b√¨nh: {age_mean:.1f}")
            insights.append(f"- S·ªë d∆∞ trung b√¨nh: {balance_mean:.0f} EUR")
            insights.append(f"- S·ªë l·∫ßn li√™n l·∫°c TB: {campaign_mean:.1f}")
            insights.append(f"- S·ªë l·∫ßn li√™n l·∫°c tr∆∞·ªõc TB: {previous_mean:.1f}")
            
            # RFM scores n·∫øu c√≥
            if 'RFM_score' in cluster_data.columns:
                rfm_mean = cluster_data['RFM_score'].mean()
                insights.append(f"- RFM score TB: {rfm_mean:.1f}")
            
            # T·ª∑ l·ªá th√†nh c√¥ng
            if 'y' in cluster_data.columns:
                success_rate = cluster_data['y'].mean() * 100
                insights.append(f"- T·ª∑ l·ªá ƒëƒÉng k√Ω th√†nh c√¥ng: {success_rate:.2f}%")
            
            # ƒê·∫∑c tr∆∞ng n·ªïi b·∫≠t
            if 'has_debt' in cluster_data.columns:
                debt_rate = cluster_data['has_debt'].mean() * 100
                insights.append(f"- C√≥ kho·∫£n vay: {debt_rate:.1f}%")
            
            if 'was_contacted_before' in cluster_data.columns:
                contacted_rate = cluster_data['was_contacted_before'].mean() * 100
                insights.append(f"- ƒê√£ t·ª´ng li√™n l·∫°c: {contacted_rate:.1f}%")
            
            # Ngh·ªÅ nghi·ªáp ph·ªï bi·∫øn
            if 'job' in cluster_data.columns:
                top_jobs = cluster_data['job'].value_counts()
                if len(top_jobs) > 0:
                    top_job = top_jobs.index[0]
                    top_job_pct = top_jobs.iloc[0] / size * 100
                    insights.append(f"- Ngh·ªÅ ph·ªï bi·∫øn: {top_job} ({top_job_pct:.1f}%)")
        
        # Th√™m insight t·ªïng h·ª£p
        insights.append("\nüìä INSIGHTS T·ªîNG H·ª¢P:")
        insights.append("‚Ä¢ C√°c c·ª•m ƒë∆∞·ª£c ph√¢n d·ª±a tr√™n h√†nh vi kh√°ch h√†ng (KH√îNG d√πng duration)")
        insights.append("‚Ä¢ C√≥ th·ªÉ x√¢y d·ª±ng chi·∫øn l∆∞·ª£c marketing ri√™ng cho t·ª´ng c·ª•m")
        
        return insights
    
    def analyze_cluster_separability(self, X, labels, feature_names):
        """Ph√¢n t√≠ch kh·∫£ nƒÉng ph√¢n t√°ch gi·ªØa c√°c c·ª•m"""
        from sklearn.manifold import TSNE
        import matplotlib.pyplot as plt
        
        # Gi·∫£m chi·ªÅu ƒë·ªÉ visualize
        tsne = TSNE(n_components=2, random_state=self.random_state)
        X_tsne = tsne.fit_transform(X)
        
        # V·∫Ω bi·ªÉu ƒë·ªì
        plt.figure(figsize=(10, 8))
        scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=labels, cmap='viridis', alpha=0.6)
        plt.colorbar(scatter)
        plt.title('t-SNE Visualization of Clusters (No duration)')
        plt.xlabel('t-SNE Component 1')
        plt.ylabel('t-SNE Component 2')
        
        # L∆∞u figure
        from pathlib import Path
        output_dir = Path('outputs/figures')
        output_dir.mkdir(parents=True, exist_ok=True)
        plt.savefig(output_dir / 'cluster_tsne.png', dpi=100, bbox_inches='tight')
        plt.close()
        
        logger.info("‚úÖ t-SNE cluster visualization saved")